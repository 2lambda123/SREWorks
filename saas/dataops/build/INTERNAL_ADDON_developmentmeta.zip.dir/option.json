{"addons":[{"addonConfig":"{}","addonId":"system-env","addonType":"RESOURCE_ADDON","addonVersion":"_","appId":"dataops","gmtCreate":1666577123000,"gmtModified":1666577123000,"id":53,"name":"system-env","namespaceId":"sreworks","stageId":"dev"},{"addonConfig":"{}","addonId":"productopsv2","addonType":"INTERNAL_ADDON","addonVersion":"_","appId":"dataops","gmtCreate":1645702680000,"gmtModified":1660022361000,"id":18,"name":"productopsv2","namespaceId":"sreworks","stageId":"dev"}],"helms":[{"appId":"dataops","componentType":"HELM","description":"","gmtCreate":1668612246000,"gmtModified":1668612444000,"helmExt":"{\"defaultValuesYaml\":\"global:\\n  # zone: cluster.local (use only if your DNS server doesn't live in the same zone as kubecost)\\n  prometheus:\\n    enabled: true\\n    #fqdn: http://kubecost-prometheus-server.c38cca9c474484bdc9873f44f733d8bcd.cn-beijing.alicontainer.com/\\n\\n  thanos:\\n    enabled: false\\n\\n  grafana:\\n    enabled: false\\n    domainName: prod-dataops-grafana.sreworks-dataops #example where format is <service-name>.<namespace>\\n    proxy: false\\n\\n  notifications:\\n    alertmanager:\\n      enabled: false # If true, allow kubecost to write to your alertmanager\\n\\n   # Set saved report(s) accessible from reports.html\\n   # Ref: http://docs.kubecost.com/saved-reports\\n  savedReports:\\n    enabled: false # If true, overwrites report parameters set through UI\\n    reports:\\n      - title: \\\"Example Saved Report 0\\\"\\n        window: \\\"today\\\"\\n        aggregateBy: \\\"namespace\\\"\\n        idle: \\\"separate\\\"\\n        accumulate: false # daily resolution\\n        filters:\\n          - property: \\\"cluster\\\"\\n            value: \\\"cluster-one,cluster*\\\" # supports wildcard filtering and multiple comma separated values\\n          - property: \\\"namespace\\\"\\n            value: \\\"kubecost\\\"\\n      - title: \\\"Example Saved Report 1\\\"\\n        window: \\\"month\\\"\\n        aggregateBy: \\\"controllerKind\\\"\\n        idle: \\\"share\\\"\\n        accumulate: false\\n        filters:\\n          - property: \\\"label\\\"\\n            value: \\\"app:cost*,environment:kube*\\\"\\n          - property: \\\"namespace\\\"\\n            value: \\\"kubecost\\\"\\n      - title: \\\"Example Saved Report 2\\\"\\n        window: \\\"2020-11-11T00:00:00Z,2020-12-09T23:59:59Z\\\"\\n        aggregateBy: \\\"service\\\"\\n        idle: \\\"hide\\\"\\n        accumulate: true # entire window resolution\\n        filters: [] # if no filters, specify empty array\\n\\n  # Set saved report(s) accessible from reports.html\\n  # Ref: http://docs.kubecost.com/saved-reports\\n  assetReports:\\n    enabled: false # If true, overwrites report parameters set through UI\\n    reports:\\n    - title: \\\"Example Asset Report 0\\\"\\n      window: \\\"today\\\"\\n      aggregateBy: \\\"type\\\"\\n      accumulate: false # daily resolution\\n      filters:\\n        - property: \\\"cluster\\\"\\n          value: \\\"cluster-one\\\"\\n\\n  podAnnotations: {}\\n    # iam.amazonaws.com/role: role-arn\\n  additionalLabels: {}\\n\\n# generated at http://kubecost.com/install, used for alerts tracking and free trials\\nkubecostToken: \\\"MzEyMTg5Mzk3QHFxLmNvbQ==xm343yadf98\\\"\\n\\nkubecostFrontend:\\n  image: \\\"sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/kubecost1/frontend\\\"\\n  imagePullPolicy: Always\\n  resources:\\n    requests:\\n      cpu: \\\"10m\\\"\\n      memory: \\\"55Mi\\\"\\n    #limits:\\n    #  cpu: \\\"100m\\\"\\n    #  memory: \\\"256Mi\\\"\\n#  tls:\\n#    enable: true\\n#    secretName:\\n\\nkubecost:\\n  # Enables the cost-analyzer-server container to spin up as part of kubecost\\n  # Setting this to false will mean all /api/ endpoints will be unavailable\\n  disableServer: false\\n  image: \\\"sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/kubecost1/server\\\"\\n  resources:\\n    requests:\\n      cpu: \\\"100m\\\"\\n      memory: \\\"55Mi\\\"\\n    #limits:\\n    #  cpu: \\\"100m\\\"\\n    #  memory: \\\"256Mi\\\"\\n\\nkubecostModel:\\n  image: \\\"sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/kubecost1/cost-model\\\"\\n  imagePullPolicy: Always\\n  # Enables the emission of the kubecost_cloud_credit_total and\\n  # kubecost_cloud_expense_total metrics\\n  outOfClusterPromMetricsEnabled: false\\n  # Build local cost allocation cache\\n  warmCache: false\\n  # Build local savings cache\\n  warmSavingsCache: true\\n  # Run allocation ETL pipelines\\n  etl: true\\n  # The total number of days the ETL pipelines will build\\n  # Set to 0 to disable daily ETL (not recommended)\\n  etlDailyStoreDurationDays: 91\\n  # The total number of hours the ETL pipelines will build\\n  # Set to 0 to disable hourly ETL (not recommended)\\n  etlHourlyStoreDurationHours: 49\\n  # max number of concurrent Prometheus queries\\n  maxQueryConcurrency: 5\\n  resources:\\n    requests:\\n      cpu: \\\"200m\\\"\\n      memory: \\\"55Mi\\\"\\n    #limits:\\n    #  cpu: \\\"800m\\\"\\n    #  memory: \\\"256Mi\\\"\\n\\n# Basic Kubecost ingress, more examples available at https://github.com/kubecost/docs/blob/master/ingress-examples.md\\ningress:\\n  enabled: false\\n  className: nginx\\n  annotations:\\n    # kubernetes.io/ingress.class: nginx\\n    # kubernetes.io/tls-acme: \\\"true\\\"\\n  paths: [\\\"/\\\"] # There's no need to route specifically to the pods-- we have an nginx deployed that handles routing\\n  pathType: ImplementationSpecific\\n  hosts:\\n    - kubecost-cost-analyzer.c38cca9c474484bdc9873f44f733d8bcd.cn-beijing.alicontainer.com\\n  tls: []\\n  #  - secretName: cost-analyzer-tls\\n  #    hosts:\\n  #      - cost-analyzer.local\\n\\n# If true, enable creation of NetworkPolicy resources.\\nnetworkPolicy:\\n  enabled: false\\n  denyEgress: true # create a network policy that denies egress from kubecost\\n  sameNamespace: true # Set to true if cost analyser and prometheus are on the same namespace\\n#  namespace: kubecost # Namespace where prometheus is installed\\n\\n  # Cost-analyzer specific vars using the new template\\n  costAnalyzer:\\n    enabled: false # If true, create a newtork policy for cost-analzyer\\n    annotations: {} # annotations to be added to the network policy\\n    additionalLabels: {} # additional labels to be added to the network policy\\n    # Examples rules:\\n    # ingressRules:\\n    #   - selectors: # allow ingress from self on all ports\\n    #     - podSelector:\\n    #         matchLabels:\\n    #           app.kubernetes.io/name: cost-analyzer\\n    #   - selectors: # allow egress access to prometheus\\n    #     - namespaceSelector:\\n    #         matchLabels:\\n    #           name: prometheus\\n    #       podSelector:\\n    #         matchLabels:\\n    #           app: prometheus\\n    #     ports:\\n    #       - protocol: TCP\\n    #         port: 9090\\n    # egressRules:\\n    #   - selectors: # restrict egress to inside cluster\\n    #     - namespaceSelector: {}\\n\\npersistentVolume:\\n  size: 100Gi\\n  dbSize: 100.0Gi\\n  enabled: true # Note that setting this to false means configurations will be wiped out on pod restart.\\n  storageClass: \\\"{{ Global.STORAGE_CLASS }}\\\"\\n  accessModes:\\n    - ReadWriteOnce\\n\\nservice:\\n  type: ClusterIP\\n  port: 9090\\n  targetPort: 9090\\n  # nodePort:\\n  labels: {}\\n  annotations: {}\\n\\nprometheus:\\n  kube-state-metrics:\\n    disabled: false\\n    image:\\n      repository: sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/kube-state-metrics\\n      tag: v1.9.8\\n      pullPolicy: Always\\n  extraScrapeConfigs: |\\n    - job_name: kubecost\\n      honor_labels: true\\n      scrape_interval: 1m\\n      scrape_timeout: 10s\\n      metrics_path: /metrics\\n      scheme: http\\n      dns_sd_configs:\\n      - names:\\n        - {{ template \\\"cost-analyzer.serviceName\\\" . }}\\n        type: 'A'\\n        port: 9003\\n    - job_name: kubecost-networking\\n      kubernetes_sd_configs:\\n        - role: pod\\n      relabel_configs:\\n      # Scrape only the the targets matching the following metadata\\n        - source_labels: [__meta_kubernetes_pod_label_app]\\n          action: keep\\n          regex:  {{ template \\\"cost-analyzer.networkCostsName\\\" . }}\\n  server:\\n    # If clusterIDConfigmap is defined, instead use user-generated configmap with key CLUSTER_ID\\n    # to use as unique cluster ID in kubecost cost-analyzer deployment.\\n    # This overrides the cluster_id set in prometheus.server.global.external_labels.\\n    # NOTE: This does not affect the external_labels set in prometheus config.\\n    # clusterIDConfigmap: cluster-id-configmap\\n\\n    resources: {}\\n    # limits:\\n    #   cpu: 500m\\n    #   memory: 512Mi\\n    # requests:\\n    #   cpu: 500m\\n    #   memory: 512Mi\\n    global:\\n      scrape_interval: 1m\\n      scrape_timeout: 10s\\n      evaluation_interval: 1m\\n      external_labels:\\n        cluster_id: cluster123 # Each cluster should have a unique ID\\n    persistentVolume:\\n      size: 100Gi\\n      enabled: true\\n      storageClass: \\\"{{ Global.STORAGE_CLASS }}\\\"\\n      accessModes:\\n        - ReadWriteOnce\\n    extraArgs:\\n      query.max-concurrency: 1\\n      query.max-samples: 100000000\\n    tolerations: []\\n    #  - key: \\\"key\\\"\\n    #    operator: \\\"Equal|Exists\\\"\\n    #    value: \\\"value\\\"\\n    #    effect: \\\"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\\\"\\n  alertmanager:\\n    enabled: false\\n    persistentVolume:\\n      enabled: true\\n  nodeExporter:\\n    enabled: true\\n    service:\\n        annotations:\\n          prometheus.io/scrape: \\\"true\\\"\\n        # Exposed as a headless service:\\n        # https://kubernetes.io/docs/concepts/services-networking/service/#headless-services\\n        clusterIP: None\\n        hostPort: 9010\\n        servicePort: 9010\\n        type: ClusterIP\\n  pushgateway:\\n    enabled: false\\n    persistentVolume:\\n      enabled: true\\n  serverFiles:\\n  #  prometheus.yml: # Sample block -- enable if using an in cluster durable store.\\n  #      remote_write:\\n  #        - url: \\\"http://pgprometheus-adapter:9201/write\\\"\\n  #          write_relabel_configs:\\n  #            - source_labels: [__name__]\\n  #              regex: 'container_.*_allocation|container_.*_allocation_bytes|.*_hourly_cost|kube_pod_container_resource_requests{resource=\\\"memory\\\", unit=\\\"byte\\\"}|container_memory_working_set_bytes|kube_pod_container_resource_requests{resource=\\\"cpu\\\", unit=\\\"core\\\"}|kube_pod_container_resource_requests|pod_pvc_allocation|kube_namespace_labels|kube_pod_labels'\\n  #              action: keep\\n  #          queue_config:\\n  #            max_samples_per_send: 1000\\n        #remote_read:\\n        #  - url: \\\"http://pgprometheus-adapter:9201/read\\\"\\n    rules:\\n      groups:\\n        - name: CPU\\n          rules:\\n            - expr: sum(rate(container_cpu_usage_seconds_total{container_name!=\\\"\\\"}[5m]))\\n              record: cluster:cpu_usage:rate5m\\n            - expr: rate(container_cpu_usage_seconds_total{container_name!=\\\"\\\"}[5m])\\n              record: cluster:cpu_usage_nosum:rate5m\\n            - expr: avg(irate(container_cpu_usage_seconds_total{container_name!=\\\"POD\\\", container_name!=\\\"\\\"}[5m])) by (container_name,pod_name,namespace)\\n              record: kubecost_container_cpu_usage_irate\\n            - expr: sum(container_memory_working_set_bytes{container_name!=\\\"POD\\\",container_name!=\\\"\\\"}) by (container_name,pod_name,namespace)\\n              record: kubecost_container_memory_working_set_bytes\\n            - expr: sum(container_memory_working_set_bytes{container_name!=\\\"POD\\\",container_name!=\\\"\\\"})\\n              record: kubecost_cluster_memory_working_set_bytes\\n        - name: Savings\\n          rules:\\n            - expr: sum(avg(kube_pod_owner{owner_kind!=\\\"DaemonSet\\\"}) by (pod) * sum(container_cpu_allocation) by (pod))\\n              record: kubecost_savings_cpu_allocation\\n              labels:\\n                daemonset: \\\"false\\\"\\n            - expr: sum(avg(kube_pod_owner{owner_kind=\\\"DaemonSet\\\"}) by (pod) * sum(container_cpu_allocation) by (pod)) / sum(kube_node_info)\\n              record: kubecost_savings_cpu_allocation\\n              labels:\\n                daemonset: \\\"true\\\"\\n            - expr: sum(avg(kube_pod_owner{owner_kind!=\\\"DaemonSet\\\"}) by (pod) * sum(container_memory_allocation_bytes) by (pod))\\n              record: kubecost_savings_memory_allocation_bytes\\n              labels:\\n                daemonset: \\\"false\\\"\\n            - expr: sum(avg(kube_pod_owner{owner_kind=\\\"DaemonSet\\\"}) by (pod) * sum(container_memory_allocation_bytes) by (pod)) / sum(kube_node_info)\\n              record: kubecost_savings_memory_allocation_bytes\\n              labels:\\n                daemonset: \\\"true\\\"\\n            - expr: label_replace(sum(kube_pod_status_phase{phase=\\\"Running\\\",namespace!=\\\"kube-system\\\"} > 0) by (pod, namespace), \\\"pod_name\\\", \\\"$1\\\", \\\"pod\\\", \\\"(.+)\\\")\\n              record: kubecost_savings_running_pods\\n            - expr: sum(rate(container_cpu_usage_seconds_total{container_name!=\\\"\\\",container_name!=\\\"POD\\\",instance!=\\\"\\\"}[5m])) by (namespace, pod_name, container_name, instance)\\n              record: kubecost_savings_container_cpu_usage_seconds\\n            - expr: sum(container_memory_working_set_bytes{container_name!=\\\"\\\",container_name!=\\\"POD\\\",instance!=\\\"\\\"}) by (namespace, pod_name, container_name, instance)\\n              record: kubecost_savings_container_memory_usage_bytes\\n            - expr: avg(sum(kube_pod_container_resource_requests{resource=\\\"cpu\\\", unit=\\\"core\\\", namespace!=\\\"kube-system\\\"}) by (pod, namespace, instance)) by (pod, namespace)\\n              record: kubecost_savings_pod_requests_cpu_cores\\n            - expr: avg(sum(kube_pod_container_resource_requests{resource=\\\"memory\\\", unit=\\\"byte\\\", namespace!=\\\"kube-system\\\"}) by (pod, namespace, instance)) by (pod, namespace)\\n              record: kubecost_savings_pod_requests_memory_bytes\\n\\n## Module for measuring network costs\\n## Ref: https://github.com/kubecost/docs/blob/master/network-allocation.md\\nnetworkCosts:\\n  enabled: false\\n  podSecurityPolicy:\\n    enabled: false\\n  image: sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/kubecost1/kubecost-network-costs\\n  tag: v15.7\\n  imagePullPolicy: Always\\n  # For existing Prometheus Installs, create a Service which generates Endpoints for each of the network-costs pods.\\n  # This Service is annotated with prometheus.io/scrape: \\\"true\\\" to automatically get picked up by the prometheus config.\\n  # NOTE: Setting this option to true and leaving the above extraScrapeConfig \\\"job_name: kubecost-networking\\\" configured will cause the\\n  # NOTE: pods to be scraped twice.\\n  prometheusScrape: false\\n  # Traffic Logging will enable logging the top 5 destinations for each source\\n  # every 30 minutes.\\n  trafficLogging: true\\n  # Port will set both the containerPort and hostPort to this value.\\n  # These must be identical due to network-costs being run on hostNetwork\\n  port: 3001\\n  resources: {}\\n    #requests:\\n    #  cpu: \\\"50m\\\"\\n    #  memory: \\\"20Mi\\\"\\n  config:\\n    # Configuration for traffic destinations, including specific classification\\n    # for IPs and CIDR blocks. This configuration will act as an override to the\\n    # automatic classification provided by network-costs.\\n    destinations:\\n      # In Zone contains a list of address/range that will be\\n      # classified as in zone.\\n      in-zone:\\n        # Loopback\\n        - \\\"127.0.0.1\\\"\\n        # IPv4 Link Local Address Space\\n        - \\\"169.254.0.0/16\\\"\\n        # Private Address Ranges in RFC-1918\\n        - \\\"10.0.0.0/8\\\" # Remove this entry if using Multi-AZ Kubernetes\\n        - \\\"172.16.0.0/12\\\"\\n        - \\\"192.168.0.0/16\\\"\\n\\n      # In Region contains a list of address/range that will be\\n      # classified as in region. This is synonymous with cross\\n      # zone traffic, where the regions between source and destinations\\n      # are the same, but the zone is different.\\n      in-region: []\\n\\n      # Cross Region contains a list of address/range that will be\\n      # classified as non-internet egress from one region to another.\\n      cross-region: []\\n\\n      # Direct Classification specifically maps an ip address or range\\n      # to a region (required) and/or zone (optional). This classification\\n      # takes priority over in-zone, in-region, and cross-region configurations.\\n      direct-classification: []\\n      # - region: \\\"us-east1\\\"\\n      #   zone: \\\"us-east1-c\\\"\\n      #   ips:\\n      #     - \\\"10.0.0.0/24\\\"\\n\\n  ## Node tolerations for server scheduling to nodes with taints\\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\\n  ##\\n  tolerations: []\\n  #  - key: \\\"key\\\"\\n  #    operator: \\\"Equal|Exists\\\"\\n  #    value: \\\"value\\\"\\n  #    effect: \\\"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\\\"\\n\\n  affinity: {}\\n\\n  ## PriorityClassName\\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass\\n  priorityClassName: []\\n  ## PodMonitor\\n  ## Allows scraping of network metrics from a dedicated prometheus operator setup\\n  podMonitor:\\n    enabled: false\\n    additionalLabels: {}\\n  additionalLabels: {}\\n  nodeSelector: {}\\n  annotations: {}\\n\\n# Kubecost Deployment Configuration\\n# Used for HA mode in Business & Enterprise tier\\nkubecostDeployment:\\n  replicas: 1\\n\\n# Kubecost Cluster Controller for Right Sizing and Cluster Turndown\\nclusterController:\\n  enabled: false\\n  image: sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/kubecost1/cluster-controller\\n  tag: v0.0.2\\n  imagePullPolicy: Always\\n\\nreporting:\\n  # Kubecost bug report feature: Logs access/collection limited to .Release.Namespace\\n  # Ref: http://docs.kubecost.com/bug-report\\n  logCollection: true\\n  # Basic frontend analytics\\n  productAnalytics: true\\n  # Report Javascript errors\\n  errorReporting: true\\n  valuesReporting: true\\n\\nserviceMonitor:\\n  enabled: false\\n  additionalLabels: {}\\n\\nprometheusRule:\\n  enabled: false\\n  additionalLabels: {}\\n\\nsupportNFS: false\\n# initChownDataImage ensures all Kubecost filepath permissions on PV or local storage are set up correctly.\\ninitChownDataImage: \\\"busybox\\\" # Supports a fully qualified Docker image, e.g. registry.hub.docker.com/library/busybox:latest\\ninitChownData:\\n  resources: {}\\n    #requests:\\n    #  cpu: \\\"50m\\\"\\n    #  memory: \\\"20Mi\\\"\\n\\n\\ngrafana:\\n  # namespace_datasources: kubecost # override the default namespace here\\n  # namespace_dashboards: kubecost # override the default namespace here\\n  sidecar:\\n    dashboards:\\n      enabled: true\\n      label: kubecost_grafana_dashboard\\n    datasources:\\n      enabled: false\\n#  For grafana to be accessible, add the path to root_url. For example, if you run kubecost at www.foo.com:9090/kubecost\\n#  set root_url to \\\"%(protocol)s://%(domain)s:%(http_port)s/kubecost/grafana\\\". No change is necessary here if kubecost runs at a root URL\\n  grafana.ini:\\n    server:\\n      root_url: \\\"%(protocol)s://%(domain)s:%(http_port)s/grafana\\\"\\n\\n#kubecostMetrics:\\n#  emitKsmV1Metrics: true # emit all KSM metrics in KSM v1.\\n#  emitKsmV1MetricsOnly: false # emit only the KSM metrics missing from KSM v2. Advanced users only.\\n\\n\\n# readonly: false # disable updates to kubecost from the frontend UI and via POST request\\n\\n# These configs can also be set from the Settings page in the Kubecost product UI\\n# Values in this block override config changes in the Settings UI on pod restart\\n#\\n#kubecostProductConfigs:\\n# An optional list of cluster definitions that can be added for frontend access. The local\\n# cluster is *always* included by default, so this list is for non-local clusters.\\n# Ref: https://github.com/kubecost/docs/blob/master/multi-cluster.md\\n#  clusters:\\n#   - name: \\\"Cluster A\\\"\\n#     address: http://cluster-a.kubecost.com:9090\\n#     # Optional authentication credentials - only basic auth is currently supported.\\n#     auth:\\n#       type: basic\\n#       # Secret name should be a secret formatted based on: https://github.com/kubecost/docs/blob/master/ingress-examples.md\\n#       secretName: cluster-a-auth\\n#       # Or pass auth directly as base64 encoded user:pass\\n#       data: YWRtaW46YWRtaW4=\\n#       # Or user and pass directly\\n#       user: admin\\n#       pass: admin\\n#   - name: \\\"Cluster B\\\"\\n#     address: http://cluster-b.kubecost.com:9090\\n#  defaultModelPricing: # default monthly resource prices, used predominately for on-prem clusters\\n#    CPU: 28.0\\n#    spotCPU: 4.86\\n#    RAM: 3.09\\n#    spotRAM: 0.65\\n#    GPU: 693.50\\n#    spotGPU: 225.0\\n#    storage: 0.04\\n#    zoneNetworkEgress: 0.01\\n#    regionNetworkEgress: 0.01\\n#    internetNetworkEgress: 0.12\\n#    enabled: true\\n#  # The cluster profile represents a predefined set of parameters to use when calculating savings.\\n#  # Possible values are: [ development, production, high-availability ]\\n#  clusterProfile: production\\n#  customPricesEnabled: false # This makes the default view custom prices-- generally used for on-premises clusters\\n#  spotLabel: lifecycle\\n#  spotLabelValue: Ec2Spot\\n#  gpuLabel: gpu\\n#  gpuLabelValue: true\\n#  awsServiceKeyName: ACCESSKEYID\\n#  awsServiceKeyPassword:  fakepassword # Only use if your values.yaml are stored encrypted. Otherwise provide an existing secret via serviceKeySecretName\\n#  awsSpotDataRegion: us-east-1\\n#  awsSpotDataBucket: spot-data-feed-s3-bucket\\n#  awsSpotDataPrefix: dev\\n#  athenaProjectID: \\\"530337586277\\\" # The AWS AccountID where the Athena CUR is. Generally your masterpayer account\\n#  athenaBucketName: \\\"s3://aws-athena-query-results-530337586277-us-east-1\\\"\\n#  athenaRegion: us-east-1\\n#  athenaDatabase: athenacurcfn_athena_test1\\n#  athenaTable: \\\"athena_test1\\\"\\n#  masterPayerARN: \\\"\\\"\\n#  projectID: \\\"123456789\\\"  # Also known as AccountID on AWS -- the current account/project that this instance of Kubecost is deployed on.\\n#  gcpSecretName: gcp-secret # Name of a secret representing the gcp service key\\n#  bigQueryBillingDataDataset: billing_data.gcp_billing_export_v1_01AC9F_74CF1D_5565A2\\n#  labelMappingConfigs:  # names of k8s labels used to designate different allocation concepts\\n#    enabled: true\\n#    owner_label: \\\"owner\\\"\\n#    team_label: \\\"team\\\"\\n#    department_label: \\\"dept\\\"\\n#    product_label: \\\"product\\\"\\n#    environment_label: \\\"env\\\"\\n#    namespace_external_label: \\\"kubernetes_namespace\\\" # external labels are used to map external cloud costs to kubernetes concepts\\n#    cluster_external_label: \\\"kubernetes_cluster\\\"\\n#    controller_external_label: \\\"kubernetes_controller\\\"\\n#    product_external_label: \\\"kubernetes_label_app\\\"\\n#    service_external_label: \\\"kubernetes_service\\\"\\n#    deployment_external_label: \\\"kubernetes_deployment\\\"\\n#    owner_external_label: \\\"kubernetes_label_owner\\\"\\n#    team_external_label: \\\"kubernetes_label_team\\\"\\n#    environment_external_label: \\\"kubernetes_label_env\\\"\\n#    department_external_label: \\\"kubernetes_label_department\\\"\\n#    statefulset_external_label: \\\"kubernetes_statefulset\\\"\\n#    daemonset_external_label: \\\"kubernetes_daemonset\\\"\\n#    pod_external_label: \\\"kubernetes_pod\\\"\\n#  grafanaURL: \\\"\\\"\\n#  clusterName: \\\"\\\" # used for display in Kubecost UI\\n#  currencyCode: \\\"USD\\\" # offical support for USD, CAD, EUR, and CHF\\n#  azureBillingRegion: US # Represents 2-letter region code, e.g. West Europe = NL, Canada = CA. ref: https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes\\n#  azureSubscriptionID: 0bd50fdf-c923-4e1e-850c-196dd3dcc5d3\\n#  azureClientID: f2ef6f7d-71fb-47c8-b766-8d63a19db017\\n#  azureTenantID: 72faf3ff-7a3f-4597-b0d9-7b0b201bb23a\\n#  azureClientPassword: fake key # Only use if your values.yaml are stored encrypted. Otherwise provide an existing secret via serviceKeySecretName\\n#  azureStorageSecretName: \\\"azure-storage-config\\\" # Name of Kubernetes Secret where Azure Storage Configuration is stored\\n#  discount: \\\"\\\" # percentage discount applied to compute\\n#  negotiatedDiscount: \\\"\\\" # custom negotiated cloud provider discount\\n#  defaultIdle: false\\n#  serviceKeySecretName: \\\"\\\" # Use an existing AWS or Azure secret with format as in aws-service-key-secret.yaml or azure-service-key-secret.yaml. Leave blank if using createServiceKeySecret\\n#  createServiceKeySecret: true # Creates a secret representing your cloud service key based on data in values.yaml. If you are storing unencrypted values, add a secret manually\\n#  sharedNamespaces: \\\"\\\" # namespaces with shared workloads, example value: \\\"kube-system\\\\,ingress-nginx\\\\,kubecost\\\\,monitoring\\\"\\n#  sharedOverhead: \\\"\\\" # value representing a fixed external cost per month to be distributed among aggregations.\\n#  shareTenancyCosts: true # enable or disable sharing costs such as cluster management fees (defaults to \\\"true\\\" on Settings page)\\n#  productKey: # apply business or enterprise product license\\n#    key: \\\"\\\"\\n#    enabled: false\\n#    secretname: productkeysecret # create a secret out of a file named productkey.json of format { \\\"key\\\": \\\"kc-b1325234\\\" }\\n#  cloudIntegrationSecret: \\\"cloud-integration\\\"\\n\\n\\n\\n\",\"repo\":{\"repoPath\":\"saas/dataops/api/kubecost/cost-analyzer\",\"branch\":\"master\",\"repo\":\"https://code.aliyun.com/sreworks_public/mirror.git\"}}","helmPackageId":"kubecost","id":27,"name":"kubecost","namespaceId":"sreworks","options":"options:\n  repoUrl: null\n  chartName: null\n  chartVersion: null\n  repo: https://code.aliyun.com/sreworks_public/mirror.git\n  ciAccount: public\n  ciToken: public\n  repoPath: saas/dataops/api/kubecost/cost-analyzer\n  branch: master\n","packageType":"REPO","stageId":"dev"},{"appId":"dataops","componentType":"HELM","description":"","gmtCreate":1666169010000,"gmtModified":1666169010000,"helmExt":"{\"defaultValuesYaml\":\"rbac:\\n  create: true\\n\\npodSecurityPolicy:\\n  enabled: false\\n\\nserviceAccounts:\\n  alertmanager:\\n    create: true\\n    name:\\n    annotations: {}\\n  nodeExporter:\\n    create: true\\n    name:\\n    annotations: {}\\n  pushgateway:\\n    create: true\\n    name:\\n    annotations: {}\\n  server:\\n    create: true\\n    name:\\n    annotations: {}\\n\\nalertmanager:\\n  enabled: false\\n\\nconfigmapReload:\\n  prometheus:\\n    enabled: false\\n  alertmanager:\\n    enabled: false\\n\\nkubeStateMetrics:\\n  enabled: false\\n\\nnodeExporter:\\n  enabled: false\\n\\n\\nserver:\\n  enabled: true\\n  persistentVolume:\\n    enabled: true\\n    accessModes:\\n      - ReadWriteOnce\\n    storageClass: \\\"{{ Global.STORAGE_CLASS }}\\\"\\n    existingClaim: \\\"\\\"\\n    mountPath: /data\\n    size: 20Gi\\n\\npushgateway:\\n  enabled: false\\n\\nserverFiles:\\n  prometheus.yml:\\n    rule_files:\\n      - /etc/config/recording_rules.yml\\n      - /etc/config/alerting_rules.yml\\n\\n    scrape_configs:\\n      - job_name: prometheus\\n        static_configs:\\n          - targets:\\n            - localhost:9090\\n      - job_name: kubernetes-pods\\n        kubernetes_sd_configs:\\n        - role: pod\\n        relabel_configs:\\n        - action: keep\\n          regex: true\\n          source_labels:\\n          - __meta_kubernetes_pod_annotation_prometheus_io_scrape\\n        - action: replace\\n          regex: (.+)\\n          source_labels:\\n          - __meta_kubernetes_pod_annotation_prometheus_io_path\\n          target_label: __metrics_path__\\n        - action: replace\\n          regex: ([^:]+)(?::\\\\d+)?;(\\\\d+)\\n          replacement: $1:$2\\n          source_labels:\\n          - __address__\\n          - __meta_kubernetes_pod_annotation_prometheus_io_port\\n          target_label: __address__\\n        - action: labelmap\\n          regex: __meta_kubernetes_pod_label_(.+)\\n        - action: replace\\n          source_labels:\\n          - __meta_kubernetes_namespace\\n          target_label: kubernetes_namespace\\n        - action: replace\\n          source_labels:\\n          - __meta_kubernetes_pod_name\\n          target_label: kubernetes_pod_name\",\"repo\":{\"repoPath\":\"saas/dataops/api/prometheus/prometheus-chart\",\"branch\":\"master\",\"repo\":\"https://code.aliyun.com/sreworks_public/mirror.git\",\"ciAccount\":\"public\",\"ciToken\":\"public\"}}","helmPackageId":"prometheus","id":26,"name":"prometheus","namespaceId":"sreworks","options":"options:\n  repoUrl: null\n  chartName: null\n  chartVersion: null\n  repo: https://code.aliyun.com/sreworks_public/mirror.git\n  ciAccount: public\n  ciToken: public\n  repoPath: saas/dataops/api/prometheus/prometheus-chart\n  branch: master\n","packageType":"REPO","stageId":"dev"},{"appId":"dataops","componentType":"HELM","description":"","gmtCreate":1665996642000,"gmtModified":1666108153000,"helmExt":"{\"defaultValuesYaml\":\"clusterName: '{{ Global.STAGE_ID }}-dataops-elasticsearch'\\nimage: sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/elasticsearch\\nimageTag: 7.10.2-with-plugins\\nreplicas: 1\\nminimumMasterNodes: 1\\nclusterHealthCheckEnable: false\\nextraEnvs:\\n  - name: cluster.initial_master_nodes\\n    value: \\\"\\\"\\n  - name: ELASTIC_PASSWORD\\n    value: \\\"{{ Global.DATA_ES_PASSWORD }}\\\"\\n  - name: ELASTIC_USERNAME\\n    value: \\\"{{ Global.DATA_ES_USER }}\\\"\\nesConfig:\\n  elasticsearch.yml: |\\n    xpack.security.enabled: true\\n    discovery.type: single-node\\n    path.data: /usr/share/elasticsearch/data\\n\\nvolumeClaimTemplate:\\n  accessModes:\\n    - ReadWriteOnce\\n  storageClassName: \\\"{{ Global.STORAGE_CLASS }}\\\"\\n  resources:\\n    requests:\\n      storage: 100Gi\",\"repo\":{\"repoPath\":\"saas/dataops/api/elasticsearch/elasticsearch-chart\",\"branch\":\"master\",\"repo\":\"https://code.aliyun.com/sreworks_public/mirror.git\"}}","helmPackageId":"elasticsearch","id":25,"name":"elasticsearch","namespaceId":"sreworks","options":"options:\n  repoUrl: null\n  chartName: null\n  chartVersion: null\n  repo: https://code.aliyun.com/sreworks_public/mirror.git\n  ciAccount: public\n  ciToken: public\n  repoPath: saas/dataops/api/elasticsearch/elasticsearch-chart\n  branch: master\n","packageType":"REPO","stageId":"dev"},{"appId":"dataops","componentType":"HELM","description":"","gmtCreate":1665996594000,"gmtModified":1666107501000,"helmExt":"{\"defaultValuesYaml\":\"image: \\\"sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/filebeat\\\"\\nimageTag: \\\"7.10.2\\\"\\npodAnnotations:\\n  name: filebeat\\nlabels:\\n  k8s-app: filebeat\\nextraEnvs:\\n  - name: NODE_NAME\\n    valueFrom:\\n      fieldRef:\\n        fieldPath: spec.nodeName\\n\\nhostNetworking: true\\n#dnsPolicy: ClusterFirstWithHostNet\\nfilebeatConfig:\\n  filebeat.yml: |\\n    filebeat.autodiscover:\\n      providers:\\n        - type: kubernetes\\n          node: ${NODE_NAME}\\n          resource: pod\\n          scope: node\\n          templates:\\n            - condition:\\n                equals:\\n                  kubernetes.labels.sreworks-telemetry-log: enable\\n              config:\\n                - type: container\\n                  paths:\\n                    - /var/log/containers/*${data.kubernetes.container.id}.log\\n                  multiline:\\n                    type: pattern\\n                    pattern: '^(\\\\[)?20\\\\d{2}-(1[0-2]|0?[1-9])-(0?[1-9]|[1-2]\\\\d|30|31)'\\n                    negate: true\\n                    match: after\\n                  processors:\\n                    - add_kubernetes_metadata:\\n                        host: ${NODE_NAME}\\n                        matchers:\\n                        - logs_path:\\n                            logs_path: \\\"/var/log/containers/\\\"\\n\\n    setup.ilm.enabled: auto\\n    setup.ilm.rollover_alias: \\\"filebeat\\\"\\n    setup.ilm.pattern: \\\"{now/d}-000001\\\"\\n    setup.template.name: \\\"filebeat\\\"\\n    setup.template.pattern: \\\"filebeat-*\\\"\\n\\n    output.elasticsearch:\\n      hosts: '{{ Global.DATA_ES_HOST }}:{{ Global.DATA_ES_PORT }}'\\n      index: \\\"filebeat-%{+yyyy.MM.dd}\\\"\\n      username: \\\"{{ Global.DATA_ES_USER }}\\\"\\n      password: \\\"{{ Global.DATA_ES_PASSWORD }}\\\"\",\"repo\":{\"repoPath\":\"saas/dataops/api/filebeat/filebeat-chart\",\"branch\":\"master\",\"repo\":\"https://code.aliyun.com/sreworks_public/mirror.git\"}}","helmPackageId":"filebeat","id":24,"name":"filebeat","namespaceId":"sreworks","options":"options:\n  repoUrl: null\n  chartName: null\n  chartVersion: null\n  repo: https://code.aliyun.com/sreworks_public/mirror.git\n  ciAccount: public\n  ciToken: public\n  repoPath: saas/dataops/api/filebeat/filebeat-chart\n  branch: master\n","packageType":"REPO","stageId":"dev"},{"appId":"dataops","componentType":"HELM","description":"","gmtCreate":1665996533000,"gmtModified":1668569340000,"helmExt":"{\"defaultValuesYaml\":\"adminUser: admin\\nadminPassword: sreworks123456\\ngrafana.ini:\\n  security:\\n    allow_embedding: true\\n  server:\\n    root_url: /gateway/dataops-grafana/\\n    serve_from_sub_path: true\\n  auth.basic:\\n    enabled: false\\n  auth.proxy:\\n    enabled: true\\n    auto_sign_up: true\\n    enable_login_token: false\\n    ldap_sync_ttl: 60\\n    sync_ttl: 60\\n    header_name: x-auth-user\\n    headers: \\\"Name:x-auth-user Email:x-auth-email-addr\\\"\\n  auth.anonymous:\\n    enabled: false\\nimage: \\n  repository: sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/grafana\\n  tag: 7.5.3\\nplugins:\\n  - marcusolsson-json-datasource\\ndatasources:\\n  datasources.yaml:\\n    apiVersion: 1\\n    datasources:\\n    - name: elasticsearch-metricbeat\\n      type: elasticsearch\\n      url: http://{{ Global.DATA_ES_HOST }}:{{ Global.DATA_ES_PORT }}\\n      database: \\\"[metricbeat]*\\\"\\n      basicAuth: true\\n      basicAuthUser: \\\"{{ Global.DATA_ES_USER }}\\\"\\n      basicAuthPassword: \\\"{{ Global.DATA_ES_PASSWORD }}\\\"\\n      access: proxy\\n      isDefault: true\\n      jsonData:\\n        interval: Yearly\\n        timeField: \\\"@timestamp\\\"\\n        esVersion: 70\\n    - name: elasticsearch-filebeat\\n      type: elasticsearch\\n      url: http://{{ Global.DATA_ES_HOST }}:{{ Global.DATA_ES_PORT }}\\n      database: \\\"[filebeat]*\\\"\\n      basicAuth: true\\n      basicAuthUser: \\\"{{ Global.DATA_ES_USER }}\\\"\\n      basicAuthPassword: \\\"{{ Global.DATA_ES_PASSWORD }}\\\"\\n      access: proxy\\n      isDefault: false\\n      jsonData:\\n        interval: Yearly\\n        timeField: \\\"@timestamp\\\"\\n        esVersion: 70\\n        logMessageField: message\\n        logLevelField: fields.level\\n    - name: dataops-prometheus\\n      type: prometheus\\n      access: proxy\\n      httpMethod: POST\\n      url: http://{{ Global.DATA_PROM_HOST}}:{{ Global.DATA_PROM_PORT }}\\n    - name: prometheus-cluster-default\\n      type: prometheus\\n      access: proxy\\n      httpMethod: POST\\n      url: http://{{ Global.DATA_PROM_HOST}}:{{ Global.DATA_PROM_PORT }}\\n    - name: dataset\\n      type: marcusolsson-json-datasource\\n      url: http://{{ Global.STAGE_ID }}-{{ Global.APP_ID }}-dataset.{{ Global.NAMESPACE_ID }}\\n      access: proxy\\n      isDefault: false\\ndashboards:\\n  flink:\\n    flink-dashboard:\\n      file: dashboards/flink-dashboard.json\\n  cost:\\n    cost-dashboard:\\n      file: dashboards/cost-dashboard.json\\ndashboardProviders:\\n  dashboardproviders.yaml:\\n    apiVersion: 1\\n    providers:\\n    - name: 'flink'\\n      orgId: 1\\n      folder: 'sreworks-dataops'\\n      type: file\\n      disableDeletion: false\\n      editable: true\\n      options:\\n        path: /var/lib/grafana/dashboards/flink\\n    - name: 'cost'\\n      orgId: 1\\n      folder: 'sreworks-dataops'\\n      type: file\\n      disableDeletion: false\\n      editable: true\\n      options:\\n        path: /var/lib/grafana/dashboards/cost\",\"repo\":{\"repoPath\":\"saas/dataops/api/grafana/grafana-chart\",\"branch\":\"master\",\"repo\":\"https://code.aliyun.com/sreworks_public/mirror.git\"}}","helmPackageId":"grafana","id":23,"name":"grafana","namespaceId":"sreworks","options":"options:\n  repoUrl: null\n  chartName: null\n  chartVersion: null\n  repo: https://code.aliyun.com/sreworks_public/mirror.git\n  ciAccount: public\n  ciToken: public\n  repoPath: saas/dataops/api/grafana/grafana-chart\n  branch: master\n","packageType":"REPO","stageId":"dev"},{"appId":"dataops","componentType":"HELM","description":"","gmtCreate":1665996486000,"gmtModified":1666111232000,"helmExt":"{\"defaultValuesYaml\":\"ingress:\\n  enabled: false\\nimage: sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/kibana\\nelasticsearchHosts: \\\"http://{{ Global.DATA_ES_HOST }}:{{ Global.DATA_ES_PORT }}\\\"\\nkibanaConfig:\\n   kibana.yml: |-\\n     elasticsearch.username: {{ Global.DATA_ES_USER }}\\n     elasticsearch.password: {{ Global.DATA_ES_PASSWORD }}\\nresources:\\n  requests:\\n    cpu: \\\"200m\\\"\\n    memory: 512Mi\\n  limits:\\n    cpu: \\\"300m\\\"\\n    memory: 512Mi\",\"repo\":{\"repoPath\":\"saas/dataops/api/kibana/kibana-chart\",\"branch\":\"master\",\"repo\":\"https://code.aliyun.com/sreworks_public/mirror.git\"}}","helmPackageId":"kibana","id":22,"name":"kibana","namespaceId":"sreworks","options":"options:\n  repoUrl: null\n  chartName: null\n  chartVersion: null\n  repo: https://code.aliyun.com/sreworks_public/mirror.git\n  ciAccount: public\n  ciToken: public\n  repoPath: saas/dataops/api/kibana/kibana-chart\n  branch: master\n","packageType":"REPO","stageId":"dev"},{"appId":"dataops","componentType":"HELM","description":"","gmtCreate":1665996426000,"gmtModified":1665996426000,"helmExt":"{\"defaultValuesYaml\":\"image: sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/metricbeat\\ndaemonset:\\n  annotations:\\n    name: metricbeat\\n  labels: \\n    k8s-app: metricbeat\\n  enabled: true\\n  extraEnvs:\\n    - name: ELASTICSEARCH_HOSTS\\n      value: \\\"{{ Global.STAGE_ID }}-dataops-elasticsearch-master.{{ Global.NAMESPACE_ID }}.svc.cluster.local\\\"\\n    - name: NODE_NAME\\n      valueFrom:\\n        fieldRef:\\n          fieldPath: spec.nodeName\\n    - name: NODE_IP\\n      valueFrom:\\n        fieldRef:\\n          fieldPath: status.hostIP\\n  hostNetworking: true\\n  #dnsPolicy: ClusterFirstWithHostNet\\n  metricbeatConfig:\\n    metricbeat.yml: |\\n      metricbeat.modules:\\n      - module: kubernetes\\n        metricsets:\\n          - container\\n          - node\\n          - pod\\n          - system\\n          - volume\\n        period: 1m\\n        host: \\\"${NODE_NAME}\\\"\\n        hosts: [\\\"https://${NODE_IP}:10250\\\"]\\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\\n        ssl.verification_mode: \\\"none\\\"\\n        # If using Red Hat OpenShift remove ssl.verification_mode entry and\\n        # uncomment these settings:\\n        ssl.certificate_authorities:\\n          - /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\\n        processors:\\n        - add_kubernetes_metadata: ~\\n      - module: kubernetes\\n        enabled: true\\n        metricsets:\\n          - event\\n      - module: kubernetes\\n        metricsets:\\n          - proxy\\n        period: 1m\\n        host: ${NODE_NAME}\\n        hosts: [\\\"localhost:10249\\\"]\\n      - module: system\\n        period: 1m\\n        metricsets:\\n          - cpu\\n          - load\\n          - memory\\n          - network\\n          - process\\n          - process_summary\\n        cpu.metrics: [percentages, normalized_percentages]\\n        processes: ['.*']\\n        process.include_top_n:\\n          by_cpu: 5\\n          by_memory: 5\\n      - module: system\\n        period: 1m\\n        metricsets:\\n          - filesystem\\n          - fsstat\\n        processors:\\n        - drop_event.when.regexp:\\n            system.filesystem.mount_point: '^/(sys|cgroup|proc|dev|etc|host|lib)($|/)'\\n\\n      metricbeat.autodiscover:\\n        providers:\\n          - type: kubernetes\\n            scope: cluster\\n            node: ${NODE_NAME}\\n            resource: service\\n            templates:\\n              - condition:\\n                  equals:\\n                    kubernetes.labels.sreworks-telemetry-metric: enable\\n                config:\\n                  - module: http\\n                    metricsets:\\n                      - json\\n                    period: 1m\\n                    hosts: [\\\"http://${data.host}:10080\\\"]\\n                    namespace: \\\"${data.kubernetes.namespace}#${data.kubernetes.service.name}\\\"\\n                    path: \\\"/\\\"\\n                    method: \\\"GET\\\"\\n\\n          - type: kubernetes\\n            scope: cluster\\n            node: ${NODE_NAME}\\n            unique: true\\n            templates:\\n              - config:\\n                  - module: kubernetes\\n                    hosts: [\\\"kubecost-kube-state-metrics.sreworks-client.svc.cluster.local:8080\\\"]\\n                    period: 1m\\n                    add_metadata: true\\n                    metricsets:\\n                      - state_node\\n                      - state_deployment\\n                      - state_daemonset\\n                      - state_replicaset\\n                      - state_pod\\n                      - state_container\\n                      - state_cronjob\\n                      - state_resourcequota\\n                      - state_statefulset\\n                      - state_service\\n\\n      processors:\\n        - add_cloud_metadata:\\n      \\n      setup.ilm.enabled: auto\\n      setup.ilm.rollover_alias: \\\"metricbeat\\\"\\n      setup.ilm.pattern: \\\"{now/d}-000001\\\"\\n      setup.template.name: \\\"metricbeat\\\"\\n      setup.template.pattern: \\\"metricbeat-*\\\"\\n\\n      output.elasticsearch:\\n        hosts: '${ELASTICSEARCH_HOSTS:{{ Global.STAGE_ID }}-dataops-elasticsearch-master:9200}'\\n        index: \\\"metricbeat-%{+yyyy.MM.dd}\\\"\\n\\n  resources:\\n    requests:\\n      cpu: \\\"100m\\\"\\n      memory: \\\"100Mi\\\"\\n    limits:\\n      cpu: \\\"1000m\\\"\\n      memory: \\\"500Mi\\\"\\ndeployment: \\n  enabled: false\\n\\nkube_state_metrics:\\n  enabled: false\\n\\nclusterRoleRules:\\n- apiGroups: [\\\"\\\"]\\n  resources:\\n  - nodes\\n  - namespaces\\n  - events\\n  - pods\\n  verbs: [\\\"get\\\", \\\"list\\\", \\\"watch\\\"]\\n- apiGroups: [\\\"extensions\\\"]\\n  resources:\\n  - replicasets\\n  verbs: [\\\"get\\\", \\\"list\\\", \\\"watch\\\"]\\n- apiGroups: [\\\"apps\\\"]\\n  resources:\\n  - statefulsets\\n  - deployments\\n  - replicasets\\n  verbs: [\\\"get\\\", \\\"list\\\", \\\"watch\\\"]\\n- apiGroups: [\\\"\\\"]\\n  resources:\\n  - nodes/stats\\n  - nodes\\n  - services\\n  - endpoints\\n  - pods\\n  verbs: [\\\"get\\\", \\\"list\\\", \\\"watch\\\"]\\n- nonResourceURLs:\\n    - \\\"/metrics\\\"\\n  verbs:\\n    - get\\n- apiGroups:\\n    - coordination.k8s.io\\n  resources:\\n    - leases\\n  verbs:\\n    - '*'\\n\\nserviceAccount: \\\"metricbeat-sa\\\" \\n\",\"repo\":{\"repoPath\":\"saas/dataops/api/metricbeat/metricbeat-chart\",\"branch\":\"master\",\"repo\":\"https://code.aliyun.com/sreworks_public/mirror.git\",\"ciAccount\":\"public\",\"ciToken\":\"public\"}}","helmPackageId":"metricbeat","id":21,"name":"metricbeat","namespaceId":"sreworks","options":"options:\n  repoUrl: null\n  chartName: null\n  chartVersion: null\n  repo: https://code.aliyun.com/sreworks_public/mirror.git\n  ciAccount: public\n  ciToken: public\n  repoPath: saas/dataops/api/metricbeat/metricbeat-chart\n  branch: master\n","packageType":"REPO","stageId":"dev"},{"appId":"dataops","componentType":"HELM","description":"","gmtCreate":1665996318000,"gmtModified":1666148958000,"helmExt":"{\"defaultValuesYaml\":\"global:\\n  storageClass: \\\"{{ Global.STORAGE_CLASS }}\\\"\\nprimary:\\n  service:\\n    type: ClusterIP\\n  persistence:\\n    size: 50Gi\\n  extraFlags: '--max-connect-errors=1000 --max_connections=10000'\\nreplication:\\n  enabled: false\\nimage:\\n  registry: sreworks-registry.cn-beijing.cr.aliyuncs.com\\n  repository: mirror/mysql\\n  tag: 8.0.22-debian-10-r44\\nauth:\\n  rootPassword: cb56b5is5e21_c359b42223\",\"repo\":{\"repoPath\":\"saas/dataops/api/mysql/mysql-chart\",\"branch\":\"master\",\"repo\":\"https://code.aliyun.com/sreworks_public/mirror.git\"}}","helmPackageId":"mysql","id":20,"name":"mysql","namespaceId":"sreworks","options":"options:\n  repoUrl: null\n  chartName: null\n  chartVersion: null\n  repo: https://code.aliyun.com/sreworks_public/mirror.git\n  ciAccount: public\n  ciToken: public\n  repoPath: saas/dataops/api/mysql/mysql-chart\n  branch: master\n","packageType":"REPO","stageId":"dev"},{"appId":"dataops","componentType":"HELM","description":"","gmtCreate":1665996240000,"gmtModified":1666857714000,"helmExt":"{\"defaultValuesYaml\":\"oap:\\n  replicas: 1\\n  image:\\n    repository: sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/skywalking-oap-server-utc-8\\n    tag: 9.2.0\\n  storageType: elasticsearch\\n  javaOpts: -Xmx1g -Xms1g\\n\\nui:\\n  image:\\n    repository: sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/skywalking-ui:9.2.0\\n    tag: 9.2.0 \\n    \\nelasticsearch:\\n  enabled: false\\n  config:\\n    host: '{{ Global.STAGE_ID }}-dataops-elasticsearch-master.{{ Global.NAMESPACE_ID }}.svc.cluster.local'\\n    port:\\n      http: 9200\\n    user: \\\"{{ Global.DATA_ES_USER }}\\\"\\n    password: \\\"{{ Global.DATA_ES_PASSWORD }}\\\"\",\"repo\":{\"repoPath\":\"saas/dataops/api/skywalking/skywalking-chart\",\"branch\":\"master\",\"repo\":\"https://code.aliyun.com/sreworks_public/mirror.git\"}}","helmPackageId":"skywalking","id":19,"name":"skywalking","namespaceId":"sreworks","options":"options:\n  repoUrl: null\n  chartName: null\n  chartVersion: null\n  repo: https://code.aliyun.com/sreworks_public/mirror.git\n  ciAccount: public\n  ciToken: public\n  repoPath: saas/dataops/api/skywalking/skywalking-chart\n  branch: master\n","packageType":"REPO","stageId":"dev"},{"appId":"dataops","componentType":"HELM","description":"","gmtCreate":1665996176000,"gmtModified":1666159031000,"helmExt":"{\"defaultValuesYaml\":\"acceptCommunityEditionLicense: true\\nvvp:\\n  registry: sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror\\n  persistence:\\n    type: local\\n  blobStorage:\\n    baseUri: s3://vvp\\n    s3:\\n      endpoint: http://sreworks-minio.sreworks:9000\\n  globalDeploymentDefaults: |\\n    spec:\\n      state: RUNNING\\n      template:\\n        spec:\\n          resources:\\n            jobmanager:\\n              cpu: 0.5\\n              memory: 1G\\n            taskmanager:\\n              cpu: 0.5\\n              memory: 1G\\n          flinkConfiguration:\\n            state.backend: filesystem\\n            taskmanager.memory.managed.fraction: 0.0 # no managed memory needed for filesystem statebackend\\n            high-availability: vvp-kubernetes\\n            metrics.reporter.prom.class: org.apache.flink.metrics.prometheus.PrometheusReporter\\n            execution.checkpointing.interval: 10s\\n            execution.checkpointing.externalized-checkpoint-retention: RETAIN_ON_CANCELLATION\\n  sqlService:\\n    pool:\\n      coreSize: 1\\n      maxSize: 1\\nblobStorageCredentials:\\n  s3:\\n    accessKeyId: \\\"{{ Global.MINIO_ACCESS_KEY }}\\\"\\n    secretAccessKey: \\\"{{ Global.MINIO_SECRET_KEY }}\\\"\\npersistentVolume:\\n  enabled: true\\n  accessModes:\\n    - ReadWriteOnce\\n  annotations: {}\\n  size: 20Gi\\n  storageClass: \\\"{{ Global.STORAGE_CLASS }}\\\"\\n  subPath: ''\",\"repo\":{\"repoPath\":\"saas/dataops/api/ververica-platform/ververica-platform-chart\",\"branch\":\"master\",\"repo\":\"https://code.aliyun.com/sreworks_public/mirror.git\"}}","helmPackageId":"ververica-platform","id":18,"name":"ververica-platform","namespaceId":"sreworks","options":"options:\n  repoUrl: null\n  chartName: null\n  chartVersion: null\n  repo: https://code.aliyun.com/sreworks_public/mirror.git\n  ciAccount: public\n  ciToken: public\n  repoPath: saas/dataops/api/ververica-platform/ververica-platform-chart\n  branch: master\n","packageType":"REPO","stageId":"dev"}],"microservices":[{"appId":"dataops","arch":"","componentType":"K8S_MICROSERVICE","description":"","gmtCreate":1665995842000,"gmtModified":1666332110000,"id":172,"microServiceExt":"{\"initContainerList\":[{\"dockerfilePath\":\"Dockerfile-db-migration\",\"name\":\"db-migration\",\"repoPath\":\"saas/dataops/api/pmdb\",\"type\":\"shell\"},{\"dockerfilePath\":\"Dockerfile\",\"name\":\"metric-flink\",\"repoPath\":\"saas/dataops/api/metric-flink\",\"type\":\"shell\"}],\"kind\":\"Deployment\",\"envKeyList\":[\"DB_HOST\",\"DB_PORT\",\"DB_USER\",\"DB_PASSWORD\",\"DB_NAME\",\"DATA_DB_HOST\",\"DATA_DB_PORT\",\"DATA_DB_USER\",\"DATA_DB_PASSWORD\",\"DATA_DB_PMDB_NAME=pmdb\",\"DATA_SKYW_HOST={{Global.STAGE_ID}}-dataops-skywalking-oap\",\"DATA_SKYW_PORT=11800\",\"DATA_SKYW_ENABLE=true\",\"KAFKA_ENDPOINT=sreworks-kafka.sreworks:9092\",\"DATA_ES_HOST\",\"DATA_ES_PORT\",\"DATA_ES_USER\",\"DATA_ES_PASSWORD\",\"DATA_DB_HEALTH_NAME=sw_saas_health\",\"MINIO_ENDPOINT=sreworks-minio.sreworks:9000\",\"MINIO_ACCESS_KEY\",\"MINIO_SECRET_KEY\",\"KAFKA_URL=sreworks-kafka.sreworks:9092\",\"ES_URL\",\"HEALTH_ENDPOINT={{Global.STAGE_ID}}-health-health.sreworks.svc.cluster.local:80\",\"VVP_ENDPOINT={{Global.STAGE_ID}}-dataops-ververica-platform-ververica-platform\"],\"repo\":{\"ciAccount\":\"public\",\"ciToken\":\"public\",\"dockerfilePath\":\"Dockerfile\",\"repo\":\"https://code.aliyun.com/sreworks_public/mirror.git\",\"repoDomain\":\"https:\",\"repoGroup\":\"\",\"repoPath\":\"saas/dataops/api/pmdb\",\"repoProject\":\"code.aliyun.com\",\"repoType\":\"THIRD_REPO\"},\"launch\":{\"gatewayAuthEnabled\":false,\"gatewayRoute\":\"/pmdb/**\",\"replicas\":1,\"servicePorts\":\"7001\"}}","microServiceId":"pmdb","name":"pmdb","namespaceId":"sreworks","options":"options:\n  kind: Deployment\n  containers:\n  - build:\n      args: {}\n      dockerfileTemplateArgs: {}\n      repo: https://code.aliyun.com/sreworks_public/mirror.git\n      dockerfileTemplate: Dockerfile\n      ciAccount: public\n      ciToken: public\n      repoPath: saas/dataops/api/pmdb\n      branch: master\n    name: pmdb\n  env:\n  - DB_HOST\n  - DB_PORT\n  - DB_USER\n  - DB_PASSWORD\n  - DB_NAME\n  - DATA_DB_HOST\n  - DATA_DB_PORT\n  - DATA_DB_USER\n  - DATA_DB_PASSWORD\n  - DATA_DB_PMDB_NAME\n  - DATA_SKYW_HOST\n  - DATA_SKYW_PORT\n  - DATA_SKYW_ENABLE\n  - KAFKA_ENDPOINT\n  - DATA_ES_HOST\n  - DATA_ES_PORT\n  - DATA_ES_USER\n  - DATA_ES_PASSWORD\n  - DATA_DB_HEALTH_NAME\n  - MINIO_ENDPOINT\n  - MINIO_ACCESS_KEY\n  - MINIO_SECRET_KEY\n  - KAFKA_URL\n  - ES_URL\n  - HEALTH_ENDPOINT\n  - VVP_ENDPOINT\n  initContainers:\n  - build:\n      args: {}\n      dockerfileTemplateArgs: {}\n      repo: https://code.aliyun.com/sreworks_public/mirror.git\n      dockerfileTemplate: Dockerfile-db-migration\n      ciAccount: public\n      ciToken: public\n      repoPath: saas/dataops/api/pmdb\n      branch: master\n    name: db-migration\n  - build:\n      args: {}\n      dockerfileTemplateArgs: {}\n      repo: https://code.aliyun.com/sreworks_public/mirror.git\n      dockerfileTemplate: Dockerfile\n      ciAccount: public\n      ciToken: public\n      repoPath: saas/dataops/api/metric-flink\n      branch: master\n    name: metric-flink\n","stageId":"dev"},{"appId":"dataops","arch":"","componentType":"K8S_MICROSERVICE","description":"","gmtCreate":1665987717000,"gmtModified":1666307771000,"id":168,"microServiceExt":"{\"initContainerList\":[{\"dockerfilePath\":\"Dockerfile-db-migration\",\"name\":\"db-migration\",\"repoPath\":\"saas/dataops/api/warehouse\",\"type\":\"shell\"}],\"kind\":\"Deployment\",\"envKeyList\":[\"DATA_DB_WAREHOUSE_NAME=sw_saas_warehouse\",\"DATA_DB_HOST\",\"DATA_DB_PORT\",\"DATA_ES_HOST\",\"DATA_ES_PORT\",\"DATA_ES_USER\",\"DATA_ES_PASSWORD\",\"DATA_DB_USER\",\"DATA_DB_PASSWORD\"],\"repo\":{\"ciAccount\":\"public\",\"ciToken\":\"public\",\"dockerfilePath\":\"Dockerfile\",\"repo\":\"https://gitee.com/sreworks/sreworks.git\",\"repoDomain\":\"https:\",\"repoGroup\":\"\",\"repoPath\":\"saas/dataops/api/warehouse\",\"repoProject\":\"gitee.com\",\"repoType\":\"THIRD_REPO\"},\"launch\":{\"gatewayAuthEnabled\":false,\"gatewayRoute\":\"/warehouse/**\",\"replicas\":1,\"servicePorts\":\"7001\"}}","microServiceId":"warehouse","name":"warehouse","namespaceId":"sreworks","options":"options:\n  kind: Deployment\n  containers:\n  - build:\n      args: {}\n      dockerfileTemplateArgs: {}\n      repo: https://gitee.com/sreworks/sreworks.git\n      dockerfileTemplate: Dockerfile\n      ciAccount: public\n      ciToken: public\n      repoPath: saas/dataops/api/warehouse\n      branch: master\n    name: warehouse\n  env:\n  - DATA_DB_WAREHOUSE_NAME\n  - DATA_DB_HOST\n  - DATA_DB_PORT\n  - DATA_ES_HOST\n  - DATA_ES_PORT\n  - DATA_ES_USER\n  - DATA_ES_PASSWORD\n  - DATA_DB_USER\n  - DATA_DB_PASSWORD\n  initContainers:\n  - build:\n      args: {}\n      dockerfileTemplateArgs: {}\n      repo: https://gitee.com/sreworks/sreworks.git\n      dockerfileTemplate: Dockerfile-db-migration\n      ciAccount: public\n      ciToken: public\n      repoPath: saas/dataops/api/warehouse\n      branch: master\n    name: db-migration\n","stageId":"dev"},{"appId":"dataops","arch":"","componentType":"K8S_MICROSERVICE","description":"","gmtCreate":1665986979000,"gmtModified":1666307802000,"id":167,"microServiceExt":"{\"initContainerList\":[{\"dockerfilePath\":\"Dockerfile-db-migration\",\"name\":\"db-migration\",\"repoPath\":\"saas/dataops/api/dataset\",\"type\":\"shell\"},{\"dockerfilePath\":\"Dockerfile-db-migration-datasource\",\"name\":\"db-migration-datasource\",\"repoPath\":\"saas/dataops/api/dataset\",\"type\":\"shell\"}],\"kind\":\"Deployment\",\"envKeyList\":[\"DATA_DB_PASSWORD\",\"DATA_DB_DATASET_NAME=sw_saas_dataset\",\"DATA_DB_PMDB_NAME=pmdb\",\"DATA_ES_HOST={{Global.STAGE_ID}}-dataops-elasticsearch-master\",\"DATA_ES_PORT=9200\",\"DATA_ES_INDEX=metricbeat-7.13.0\",\"DATA_DB_DATASOURCE_NAME=sw_saas_datasource\",\"DATA_SKYW_HOST={{Global.STAGE_ID}}-dataops-skywalking-oap\",\"DATA_SKYW_PORT=11800\",\"DATA_SKYW_ENABLE=true\",\"DATA_DB_HOST\",\"DATA_DB_PORT\",\"DATA_ES_USER\",\"DATA_ES_PASSWORD\",\"DATA_DB_USER\"],\"repo\":{\"ciAccount\":\"public\",\"ciToken\":\"public\",\"dockerfilePath\":\"Dockerfile\",\"repo\":\"https://gitee.com/sreworks/sreworks.git\",\"repoDomain\":\"https:\",\"repoGroup\":\"\",\"repoPath\":\"saas/dataops/api/dataset\",\"repoProject\":\"gitee.com\",\"repoType\":\"THIRD_REPO\"},\"launch\":{\"gatewayAuthEnabled\":false,\"gatewayRoute\":\"/dataset/**\",\"replicas\":1,\"servicePorts\":\"7001\"}}","microServiceId":"dataset","name":"dataset","namespaceId":"sreworks","options":"options:\n  kind: Deployment\n  containers:\n  - build:\n      args: {}\n      dockerfileTemplateArgs: {}\n      repo: https://gitee.com/sreworks/sreworks.git\n      dockerfileTemplate: Dockerfile\n      ciAccount: public\n      ciToken: public\n      repoPath: saas/dataops/api/dataset\n      branch: master\n    name: dataset\n  env:\n  - DATA_DB_PASSWORD\n  - DATA_DB_DATASET_NAME\n  - DATA_DB_PMDB_NAME\n  - DATA_ES_HOST\n  - DATA_ES_PORT\n  - DATA_ES_INDEX\n  - DATA_DB_DATASOURCE_NAME\n  - DATA_SKYW_HOST\n  - DATA_SKYW_PORT\n  - DATA_SKYW_ENABLE\n  - DATA_DB_HOST\n  - DATA_DB_PORT\n  - DATA_ES_USER\n  - DATA_ES_PASSWORD\n  - DATA_DB_USER\n  initContainers:\n  - build:\n      args: {}\n      dockerfileTemplateArgs: {}\n      repo: https://gitee.com/sreworks/sreworks.git\n      dockerfileTemplate: Dockerfile-db-migration\n      ciAccount: public\n      ciToken: public\n      repoPath: saas/dataops/api/dataset\n      branch: master\n    name: db-migration\n  - build:\n      args: {}\n      dockerfileTemplateArgs: {}\n      repo: https://gitee.com/sreworks/sreworks.git\n      dockerfileTemplate: Dockerfile-db-migration-datasource\n      ciAccount: public\n      ciToken: public\n      repoPath: saas/dataops/api/dataset\n      branch: master\n    name: db-migration-datasource\n","stageId":"dev"}]}